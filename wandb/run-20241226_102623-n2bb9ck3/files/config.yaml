_wandb:
    value:
        cli_version: 0.19.1
        code_path: code/ppo-energy.py
        m: []
        python_version: 3.10.16
        t:
            "1":
                - 1
                - 49
                - 55
                - 105
            "2":
                - 1
                - 49
                - 55
                - 105
            "3":
                - 13
                - 15
                - 16
                - 23
                - 55
            "4": 3.10.16
            "5": 0.19.1
            "8":
                - 5
            "12": 0.19.1
            "13": linux-x86_64
anneal_lr:
    value: false
batch_size:
    value: 204800
capture_video:
    value: true
checkpoint:
    value: null
clip_coef:
    value: 0.2
clip_vloss:
    value: false
control_mode:
    value: pd_joint_delta_pos
cuda:
    value: true
ent_coef:
    value: 0
env_cfg:
    value:
        control_mode: pd_joint_delta_pos
        env_horizon: 100
        env_id: TwoRobotPickCube-v1
        num_envs: 2048
        obs_mode: state
        partial_reset: true
        render_mode: rgb_array
        reward_mode: normalized_dense
        sim_backend: gpu
env_id:
    value: TwoRobotPickCube-v1
eval_env_cfg:
    value:
        control_mode: pd_joint_delta_pos
        env_horizon: 100
        env_id: TwoRobotPickCube-v1
        num_envs: 8
        obs_mode: state
        partial_reset: false
        render_mode: rgb_array
        reward_mode: normalized_dense
        sim_backend: gpu
eval_freq:
    value: 10
eval_partial_reset:
    value: false
eval_reconfiguration_freq:
    value: 1
evaluate:
    value: false
exp_name:
    value: ppo-energy
finite_horizon_gae:
    value: true
gae_lambda:
    value: 0.9
gamma:
    value: 0.8
learning_rate:
    value: 0.0003
max_grad_norm:
    value: 0.5
minibatch_size:
    value: 6400
norm_adv:
    value: true
num_envs:
    value: 2048
num_eval_envs:
    value: 8
num_eval_steps:
    value: 100
num_iterations:
    value: 244
num_minibatches:
    value: 32
num_steps:
    value: 100
partial_reset:
    value: true
reconfiguration_freq:
    value: null
reward_scale:
    value: 1
save_model:
    value: true
save_train_video_freq:
    value: null
seed:
    value: 3407
target_kl:
    value: 0.1
torch_deterministic:
    value: true
total_timesteps:
    value: 50000000
track:
    value: true
update_epochs:
    value: 8
vf_coef:
    value: 0.5
wandb_entity:
    value: null
wandb_project_name:
    value: ManiSkill
